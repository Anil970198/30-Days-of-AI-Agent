# ğŸ™ Conversational Voice Agent

ğŸ—£ï¸ **Talk to your AI â€” get human-like responses back in real time.**  
Powered by **AssemblyAI** (Speech-to-Text) + **Google Gemini** (LLM) + **Murf AI** (Text-to-Speech).  
Built as part of **#30DaysofVoiceAgents** by [Murf AI](https://murf.ai).

---

## ğŸ“¸ UI Screenshots
*(Add screenshots here â€” one for the main chat interface, one for the architecture diagram)*

---

## âœ¨ Whatâ€™s Inside

- ğŸ™ **Hands-free voice chat** â€” Record directly in your browser and hear AI responses instantly.
- ğŸ§  **Multi-turn memory** â€” Session-based conversation history (tracked with `session_id`).
- ğŸ›¡ **Resilient by design** â€” Graceful fallbacks if STT, LLM, or TTS fails (no awkward silence).
- âš¡ **FastAPI backend** â€” Clean, async endpoints for TTS, STT, LLM, and agent chat.
- ğŸ¨ **Simple, responsive UI** â€” Built with HTML/CSS/JS (and easily replaceable with Tailwind).
- ğŸ” **Auto-continue mode** â€” Automatically restarts recording after AI finishes speaking.

---

## ğŸ§© High-Level Architecture

```plaintext
User Speaks â†’ AssemblyAI (STT) â†’ Google Gemini (LLM) â†’ Murf AI (TTS) â†’ User Hears Reply
```

**Flow:**
1. **Frontend** captures microphone input (MediaRecorder API).
2. **Backend** sends audio to AssemblyAI for transcription.
3. Transcribed text is passed to Google Gemini for intelligent response generation.
4. Geminiâ€™s text output is sent to Murf AI for lifelike voice synthesis.
5. Final audio is streamed back to the browser and auto-played.

---

## ğŸ—‚ Project Structure

```
.
â”œâ”€ main.py                # FastAPI app (STT/LLM/TTS endpoints + agent chat)
â”œâ”€ templates/
â”‚  â””â”€ index.html           # Frontend interface
â”œâ”€ static/
â”‚  â”œâ”€ script.js            # Frontend logic (recording, fetch, playback)
â”‚  â”œâ”€ fallback.mp3         # Fallback audio when APIs fail
â”œâ”€ uploads/                # Temporary audio files
â”œâ”€ .env                    # API keys (not committed)
â”œâ”€ requirements.txt        # Python dependencies
â””â”€ README.md               # Documentation
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the root directory:

```
MURF_API_KEY=your_murf_api_key_here
ASSEMBLYAI_API_KEY=your_assemblyai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-flash
```

**Tip:** Never commit `.env` â€” add it to `.gitignore`.

---

## âš™ï¸ Setup & Run

### 1ï¸âƒ£ Clone & Create Virtual Environment
```bash
git clone https://github.com/yourusername/ai-voice-agent.git
cd ai-voice-agent

python -m venv venv
# macOS/Linux
source venv/bin/activate
# Windows
venv\Scripts\activate
```

### 2ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Start the Server
```bash
uvicorn main:app --reload
```

### 4ï¸âƒ£ Open in Browser
Go to: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## ğŸ”Œ API Endpoints (Quick Reference)

### **POST /generate-audio**
- **Body:** `{"text": "Hello world"}`
- **Response:** `{"ok": true, "audio_url": "https://..."}`  
  Falls back to `/static/fallback.mp3` if TTS fails.

### **POST /transcribe/file**
- **FormData:** `file` (audio/webm)
- **Response:** `{"ok": true, "transcript": "..."}`

### **POST /llm/query**
- **Body:** `{"text": "Your question here"}`
- **Response:** `{"ok": true, "llm_text": "..."}`

### **POST /agent/chat/{session_id}**
- **FormData:** `file` (audio/webm)
- **Response:** `{"ok": true, "transcript": "...", "llm_text": "...", "audio_url": "..."}`  
  Stores conversation history in memory for that `session_id`.

---

## ğŸ§± Error Handling & Fallbacks

- Every external API call (STT, LLM, TTS) is wrapped in **`try/except`** blocks.
- If a stage fails:
  1. Backend returns JSON with `ok: false`, `stage`, and `error`.
  2. Frontend auto-plays `fallback.mp3` so the conversation never "goes silent".
- Simulate outages by removing an API key from `.env` and restarting.

**Example Error JSON:**
```json
{
  "ok": false,
  "stage": "llm",
  "error": "RuntimeError: Gemini HTTP 403: ...details..."
}
```

---

## ğŸ§­ Browser Notes

- Uses **MediaRecorder** with `audio/webm;codecs=opus` â€” works best in Chromium-based browsers.
- Safari users may need to allow microphone permissions and check codec support.
- Autoplay is triggered after a **user gesture** to comply with browser policies.

---

## ğŸ§° Requirements (Partial List)

- `fastapi`
- `uvicorn`
- `python-dotenv`
- `requests`
- `assemblyai`
- `jinja2`

*(See `requirements.txt` for full list)*

---

## ğŸ›£ Roadmap

- Replace in-memory history with a persistent store (SQLite/Redis/Firestore)
- Add **multi-voice and style control** for Murf AI
- Implement **streamed STT & streamed TTS**
- Add **live waveform visualizer** for recordings
- Create **admin dashboard** for viewing conversation logs

---

## ğŸ™ Credits

- **[Murf AI](https://murf.ai)** â€” Text-to-Speech
- **[AssemblyAI](https://assemblyai.com)** â€” Speech-to-Text
- **[Google Gemini](https://ai.google.dev/)** â€” LLM Responses
- **[FastAPI](https://fastapi.tiangolo.com/)** â€” Backend framework

---

## ğŸ“œ License

MIT â€” see `LICENSE` file.
